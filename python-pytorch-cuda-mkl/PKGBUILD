# Maintainer: Sven-Hendrik Haase <sh@lutzhaase.com>
# Contributor: Stephen Zhang <zsrkmyn at gmail dot com>

pkgname="python-pytorch-cuda-mkl"
_pkgname="pytorch"
pkgver=1.1.0
pkgrel=3
pkgdesc="Tensors and Dynamic neural networks in Python with strong GPU acceleration"
arch=('x86_64')
_github="pytorch/pytorch"
url="http://pytorch.org"
license=('BSD')
depends=('google-glog' 'gflags' 'opencv' 'openmp' 'nccl' 'pybind11' 'python' 'python-yaml' 'python-numpy'
         'protobuf' 'ffmpeg' 'cuda' 'cudnn' 'magma' 'intel-mkl')
makedepends=('git' 'cmake' 'python-setuptools')
provides=('python-pytorch')
conflicts=('python-pytorch')
source=(
  "${_pkgname}::git+https://github.com/pytorch/pytorch.git#tag=v$pkgver"
)
sha256sums=('SKIP')

get_pyver () {
  python -c 'import sys; print(str(sys.version_info[0]) + "." + str(sys.version_info[1]))'
}

prepare() {
  cd "${_pkgname}"

  git submodule update --init --recursive

  #cp -a "${srcdir}/${_pkgname}-${pkgver}" "${srcdir}/${_pkgname}-${pkgver}-cuda"
  export CC=gcc
  export CXX=g++
  export PYTORCH_BUILD_VERSION="${pkgver}"
  export PYTORCH_BUILD_NUMBER=1

  export USE_MKLDNN=0
  # export BUILD_CUSTOM_PROTOBUF=0
  # export BUILD_SHARED_LIBS=0
  export USE_FFMPEG=1
  export USE_GFLAGS=1
  export USE_GLOG=1
  export BUILD_BINARY=1
  export USE_OPENCV=1
  export USE_SYSTEM_NCCL=1
  export MAGMA_HOME=/opt/magma
  export CUDAHOSTCXX=g++
  export CUDA_HOME=/opt/cuda
  export CUDNN_LIB_DIR=/usr/lib
  export CUDNN_INCLUDE_DIR=/usr/include
  export TORCH_NVCC_FLAGS="-Xfatbin -compress-all"
  #export TORCH_CUDA_ARCH_LIST="3.5 5.2 6.0 6.1 7.0 7.5+PTX"
}

build() {
  #msg2 "Building Python 3 without cuda"
  #cd "$srcdir/${_pkgname}-${pkgver}-py3"
  #CMAKE_PREFIX_PATH=/opt/intel/mkl/include:/opt/intel/mkl/lib/intel64 \
  #USE_CUDA=0 \
  #USE_CUDNN=0 \
  #USE_OPENCV=1 \
  #python setup.py build

  msg2 "Building with cuda"
  cd "$srcdir/${_pkgname}"
  # Uncomment and modify the following line to enable Intel MKL and magma support
  #export CMAKE_PREFIX_PATH=/opt/intel/mkl/include:/opt/intel/mkl/lib/intel64:
  export USE_CUDA=1
  export USE_CUDNN=1
  # add following line for multiple compute capabilities
  python setup.py build
}

package() {
  cd "$srcdir/${_pkgname}"
  # Prevent setup.py from re-running CMake and rebuilding
  sed -e 's/RUN_BUILD_DEPS = True/RUN_BUILD_DEPS = False/g' -i setup.py

  python setup.py install --root="$pkgdir"/ --optimize=1 --skip-build

  install -Dm644 LICENSE "${pkgdir}/usr/share/licenses/${pkgname}/LICENSE"

  pytorchpath="usr/lib/python$(get_pyver)/site-packages/torch"
  install -d "${pkgdir}/usr/lib"

  # put CMake files in correct place
  mv "${pkgdir}/${pytorchpath}/share/cmake" "${pkgdir}/usr/lib/cmake/"

  # put C++ API in correct place
  mv "${pkgdir}/${pytorchpath}/include" "${pkgdir}/usr/include"
  mv "${pkgdir}/${pytorchpath}/lib"/*.so* "${pkgdir}/usr/lib/"

  # clean up duplicates
  # TODO: move towards direct shared library dependecy of:
  #   c10, caffe2, libcpuinfo, CUDA RT, gloo, GTest, Intel MKL,
  #   NVRTC, ONNX, protobuf, libthreadpool, QNNPACK
  rm -rf "${pkgdir}/usr/include/pybind11"

  # python module is hardcoded to look there at runtime
  ln -s /usr/include "${pkgdir}/${pytorchpath}/include"
  find "${pkgdir}"/usr/lib -type f -name "*.so*" -print0 | while read -rd $'\0' _lib; do
    ln -s ${_lib#"$pkgdir"} "${pkgdir}/${pytorchpath}/lib/"
  done
}

# vim:set ts=2 sw=2 et:
